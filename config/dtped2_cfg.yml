num_frames: &num_frames 16
# dataPath: 'E:/dataset/UCSD/UCSDped1/video/label/'
#ped2 dataset
train_dataPath: 'E:/dataset/UCSD/UCSDped2/label/train.csv'
val_dataPath: 'E:/dataset/UCSD/UCSDped2/label/test.csv'
tst_dataPath: 'E:/dataset/UCSD/UCSDped2/label/test.csv'

bgPth: 'dataset/bg/ped2Bg.pt'
#color images, avenue dataset for patch
#mean: [0.1004, 0.0956, 0.0938]
#std: [0.2121, 0.2025, 0.2027]


#color image, ped2 dataset for images without bg shortSide_size:240 crop_size: [3, 8, 40, 40]
#mean: [0.3974, 0.3828, 0.3863]
#std: [0.2570, 0.2439, 0.2563]

#removing the background 48*48
#mean: [0.0310, 0.0310, 0.0310]
#std: [0.1997, 0.1895, 0.1909]

#64*64
mean: [0.0284, 0.0284, 0.0284]
std: [0.1138, 0.1138, 0.1138]

frames_per_second: 30
# side_size: 200
#if shortSide_size: 160, and crop_size: [3, 8, 160, 280], do the detection on whole image
crop_size: [3, 8, 40, 40] # patch size h,w is x*4

# device_number: 1
batch_size: 5
num_works: 0
#ped2
#shortSide_size: 240 # resized short size of video frame and keep the width/height radio
shortSide_size: 240

#ped2 dataset
#raw_shape: [3, 16, 240, 360] # original size of video frame
#avenue dataset
raw_shape: [3, *num_frames, 240, 360] # original size of video frame
train_dt_sampler: 'random'
val_dt_sampler: 'uniform'
stride: 16


